{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec90de6c",
   "metadata": {},
   "source": [
    "# Revisiting the Strategies in Federated Learning\n",
    "\n",
    "As mentioned in the previous unit, Strategies are at the core of federated learning. They determine how clients are selected, which updates are used, and how the new changes are aggregated.\n",
    "\n",
    "In this unit, we will focus on custom Strategies. To begin, we need to set up the environment for this notebook's development.\n",
    "\n",
    "### Exercise\n",
    "As you are familiar with one of the deep learning frameworks, you can implement the following part based on your preference, either PyTorch, Tensorflow, or JAX.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5d8daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:47:33.129068: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Tuple, Union, Optional\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import flwr as fl\n",
    "\n",
    "##############\n",
    "#    DATA    #\n",
    "##############\n",
    "\n",
    "#Load the CIFAR-10 in different subsets for the training and test as it has been in the previous unit\n",
    "def load_dataset():\n",
    "    # Load data\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    # Normalize data\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    # Pick only 10000 samples for training and 1000 for testing\n",
    "    x_train, y_train = x_train[:10_000], y_train[:10_000]\n",
    "    x_test, y_test = x_test[:1000], y_test[:1000]\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def split_index(a, n):\n",
    "    s = np.array_split(np.arange(len(a)), n)\n",
    "    return s\n",
    "\n",
    "def split_dataset(train_dataset, test_dataset, n_clients):\n",
    "    (x_train, y_train), (x_test, y_test) = train_dataset, test_dataset\n",
    "\n",
    "    # Randomize the datasets\n",
    "    x_train, y_train = unison_shuffled_copies(x_train, y_train)\n",
    "    x_test, y_test = unison_shuffled_copies(x_test, y_test)\n",
    "\n",
    "    # Split training set into 10 partitions to simulate the individual dataset\n",
    "    train_index = split_index(x_train, n_clients)\n",
    "    test_index = split_index(x_test, n_clients)\n",
    "\n",
    "    # Split each partition\n",
    "    train_ds = []\n",
    "    val_ds = []\n",
    "    test_ds = []\n",
    "    for cid in range(n_clients):\n",
    "        val_size = len(train_index[cid]) // 10\n",
    "        train_input_data, train_output_data = x_train[train_index[cid]], y_train[train_index[cid]]\n",
    "        val_input_data, val_output_data = train_input_data[:val_size], train_output_data[:val_size]\n",
    "        train_input_data, train_output_data = train_input_data[val_size:], train_output_data[val_size:]\n",
    "        train_dataset = (train_input_data, train_output_data)\n",
    "        val_dataset = (val_input_data, val_output_data)\n",
    "        test_dataset = (x_test[test_index[cid]], y_test[test_index[cid]])\n",
    "        train_ds.append(train_dataset)\n",
    "        val_ds.append(val_dataset)\n",
    "        test_ds.append(test_dataset)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "n_clients = 10\n",
    "train_dataset, test_dataset = load_dataset()\n",
    "train_datasets, val_datasets, test_datasets = split_dataset(train_dataset, test_dataset, n_clients)\n",
    "\n",
    "###############\n",
    "#    MODEL    #\n",
    "###############\n",
    "\n",
    "# Define a simple model using TensorFlow\n",
    "def generate_ann():\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "###################\n",
    "#    FL CLIENT    #\n",
    "###################\n",
    "\n",
    "def get_parameters(model) -> List[np.ndarray]:\n",
    "    return model.get_weights()\n",
    "\n",
    "\n",
    "def set_parameters(model, parameters: List[np.ndarray]):\n",
    "    model.set_weights(parameters)\n",
    "    return model\n",
    "\n",
    "def train(model, train_dataset, epochs: int):\n",
    "    model.fit(train_dataset[0], train_dataset[1],\n",
    "            epochs=epochs, batch_size=32, steps_per_epoch=3)\n",
    "    return model\n",
    "\n",
    "def test(model, test_dataset):\n",
    "    loss, accuracy = model.evaluate(test_dataset[0], test_dataset[1])\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "# Define the Client class to hold the functions get_parameters, fit and evaluate\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        self.net = set_parameters(self.net, parameters)\n",
    "        self.net = train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        self.net = set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        print(f\"[Client {self.cid}] loss:{loss}, accuracy:{accuracy}\")\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "# Also you can define the generation function of CLients for a stateless version\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    # Create the model\n",
    "    net = generate_ann()\n",
    "    #Take the appropiate part of the dataset\n",
    "    trainloader = train_datasets[int(cid)]\n",
    "    valloader = val_datasets[int(cid)]\n",
    "    #Create and return the Client\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf38ccc",
   "metadata": {},
   "source": [
    "Considering the previous code, the model developed has several possibilities for implementing the Strategy object such as `FedAvg` or `FedAdagrad`,  as seen in the  previous Unit. For example, the following code should create a strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae7b13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 18:33:15.778654: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO flwr 2023-03-09 18:33:16,933 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-03-09 18:33:26,583\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO flwr 2023-03-09 18:33:31,449 | app.py:179 | Flower VCE: Ray initialized with resources: {'CPU': 4.0, 'node:127.0.0.1': 1.0, 'object_store_memory': 1033074278.0, 'memory': 2066148558.0}\n",
      "INFO flwr 2023-03-09 18:33:31,454 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-03-09 18:33:31,455 | server.py:266 | Using initial parameters provided by strategy\n",
      "INFO flwr 2023-03-09 18:33:31,471 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2023-03-09 18:33:31,486 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-03-09 18:33:31,509 | server.py:215 | fit_round 1: strategy sampled 3 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25947)\u001b[0m 2023-03-09 18:33:36.130861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25947)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25946)\u001b[0m 2023-03-09 18:33:36.131269: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25946)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25945)\u001b[0m 2023-03-09 18:33:36.132272: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25945)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25947)\u001b[0m 2023-03-09 18:33:51.756821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25947)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25946)\u001b[0m 2023-03-09 18:33:51.756377: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25946)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25945)\u001b[0m 2023-03-09 18:33:51.756345: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25945)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=25947)\u001b[0m [Client 1] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25945)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25946)\u001b[0m [Client 0] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:33:54,880 | server.py:229 | fit_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2023-03-09 18:33:54,910 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-03-09 18:33:54,912 | server.py:165 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 13ms/step - loss: 2.4325 - accuracy: 0.1458\n",
      "3/3 [==============================] - 2s 17ms/step - loss: 2.4563 - accuracy: 0.1250\n",
      "3/3 [==============================] - 2s 14ms/step - loss: 2.5331 - accuracy: 0.1042\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25946)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25945)\u001b[0m [Client 8] evaluate, config: {}\n",
      "2/4 [==============>...............] - ETA: 0s - loss: 2.2836 - accuracy: 0.1250\n",
      "4/4 [==============================] - 1s 24ms/step - loss: 2.2507 - accuracy: 0.1500\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25946)\u001b[0m [Client 1] loss:2.2506637573242188, accuracy:0.15000000596046448\n",
      "4/4 [==============================] - 1s 14ms/step - loss: 2.3590 - accuracy: 0.1100\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25945)\u001b[0m [Client 8] loss:2.3590002059936523, accuracy:0.10999999940395355\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25946)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:34:04,069 | server.py:179 | evaluate_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2023-03-09 18:34:04,070 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-03-09 18:34:04,073 | server.py:215 | fit_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 2s - loss: 2.3457 - accuracy: 0.1562\n",
      "4/4 [==============================] - 1s 30ms/step - loss: 2.2871 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25946)\u001b[0m [Client 2] loss:2.2870867252349854, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25946)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25945)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25947)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25947)\u001b[0m \n",
      "1/3 [=========>....................] - ETA: 7s - loss: 2.3752 - accuracy: 0.0625\n",
      "1/3 [=========>....................] - ETA: 8s - loss: 2.4221 - accuracy: 0.0312\n",
      "3/3 [==============================] - 4s 64ms/step - loss: 2.3521 - accuracy: 0.0938\n",
      "3/3 [==============================] - 4s 20ms/step - loss: 2.3031 - accuracy: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:34:17,002 | server.py:229 | fit_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-03-09 18:34:17,029 | server.py:165 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 15ms/step - loss: 2.3545 - accuracy: 0.1042\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25947)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25947)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25945)\u001b[0m [Client 7] evaluate, config: {}\n",
      "1/4 [======>.......................] - ETA: 5s - loss: 2.2543 - accuracy: 0.0938\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25946)\u001b[0m [Client 0] evaluate, config: {}\n",
      "4/4 [==============================] - 2s 80ms/step - loss: 2.3103 - accuracy: 0.1300\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25947)\u001b[0m [Client 1] loss:2.3103127479553223, accuracy:0.12999999523162842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:34:28,656 | server.py:179 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-03-09 18:34:28,658 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step - loss: 2.2788 - accuracy: 0.1300\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25945)\u001b[0m [Client 7] loss:2.2788491249084473, accuracy:0.12999999523162842\n",
      "4/4 [==============================] - 1s 5ms/step - loss: 2.2981 - accuracy: 0.1900\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25946)\u001b[0m [Client 0] loss:2.298067569732666, accuracy:0.1899999976158142\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25946)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25945)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=25947)\u001b[0m [Client 1] fit, config: {}\n",
      "3/3 [==============================] - 2s 6ms/step - loss: 2.3269 - accuracy: 0.1458\n",
      "3/3 [==============================] - 2s 9ms/step - loss: 2.3428 - accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:34:35,719 | server.py:229 | fit_round 3 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-03-09 18:34:35,757 | server.py:165 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 2s - loss: 2.4329 - accuracy: 0.0312\n",
      "3/3 [==============================] - 1s 6ms/step - loss: 2.4127 - accuracy: 0.0521\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25945)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25947)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25946)\u001b[0m [Client 7] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:34:39,852 | server.py:179 | evaluate_round 3 received 3 results and 0 failures\n",
      "INFO flwr 2023-03-09 18:34:39,853 | server.py:144 | FL finished in 68.34607747301925\n",
      "INFO flwr 2023-03-09 18:34:39,865 | app.py:202 | app_fit: losses_distributed [(1, 2.2989168961842856), (2, 2.295743147532145), (3, 2.293851375579834)]\n",
      "INFO flwr 2023-03-09 18:34:39,868 | app.py:203 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2023-03-09 18:34:39,869 | app.py:204 | app_fit: losses_centralized []\n",
      "INFO flwr 2023-03-09 18:34:39,869 | app.py:205 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step - loss: 2.2768 - accuracy: 0.1100\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25947)\u001b[0m [Client 3] loss:2.2767512798309326, accuracy:0.10999999940395355\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 2.3008 - accuracy: 0.1000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25945)\u001b[0m [Client 9] loss:2.300809860229492, accuracy:0.10000000149011612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 2.2989168961842856\n",
       "\tround 2: 2.295743147532145\n",
       "\tround 3: 2.293851375579834"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step - loss: 2.3040 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=25946)\u001b[0m [Client 7] loss:2.303992986679077, accuracy:0.07999999821186066\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model and get the parameters\n",
    "params = get_parameters(generate_ann())\n",
    "\n",
    "# Pass parameters to the Strategy for server-side parameter initialization\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.3, # percentage of clients used for training\n",
    "    fraction_evaluate=0.3, # percentage of clients used for evaluation\n",
    "    min_fit_clients=3, # Never sample less than 'min_fit_clients' clients for training\n",
    "    min_evaluate_clients=3, #Never sample less than 'min_evaluate_clients' clients for evaluation\n",
    "    min_available_clients=10, # Wait until 'min_available_clients' clients are available\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(params), # Initial model parameters\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b8323",
   "metadata": {},
   "source": [
    "It may be worth mentioning that Flower, by default, initializes the global model by making a call to one random client before distributing it to the remaining clients. However, sometimes more control is required, such as when performing fine-tuning. In such situations, we use server-side initialization, and the `initial_parameters` parameter will hold the initial version of the model for all clients. It is important to note that this parameter must be a serialization of the data, so the utility function `ndarrays_to_parameters` can be quite handy in this case.\n",
    "\n",
    "Now, let's move on to customizing the type of evaluation performed on the models. Broadly speaking, there are two possibilities: server-side evaluation and client-side evaluation.\n",
    "\n",
    "**Centralized evaluation** (server-side) is similar to traditional machine learning, where the server holds a partition solely for evaluating the aggregated model. This approach reduces communication and is suitable for situations with limited bandwidth. There is no need to send the model to the clients for evaluation, and the entire evaluation dataset is available at all times.\n",
    "\n",
    "**Federated evaluation** (client-side) is more complex, but it usually represents real-world scenarios more accurately. In this approach, the evaluation dataset is distributed among the clients, which means that we can leverage a larger dataset spread among the resources of the clients. However, this approach comes with a cost. Since we don't have a central dataset, we should be aware that our evaluation dataset can change over consecutive rounds of learning if some clients are not always available. Moreover, the dataset held by each client can also change over consecutive rounds. This can lead to evaluation results that are not stable, so even if we don't change the model, we can see our evaluation results fluctuate over consecutive rounds. Additionally, this approach can significantly increase the number of communications because the models have to be distributed among the clients and retrieved for evaluation.\n",
    "\n",
    "The previous code snippet is an example of Flower performing Federated evaluations, as it uses the `evaluation` function that is executed on each `Client` and later aggregated after being sent to the server. On the other hand, a Centralized evaluation could be performed with a similar approach, as shown in the following code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "788a1b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-03-09 18:41:34,228 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-03-09 18:41:46,616\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO flwr 2023-03-09 18:41:51,492 | app.py:179 | Flower VCE: Ray initialized with resources: {'memory': 2440962048.0, 'CPU': 4.0, 'object_store_memory': 1220481024.0, 'node:127.0.0.1': 1.0}\n",
      "INFO flwr 2023-03-09 18:41:51,497 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-03-09 18:41:51,498 | server.py:266 | Using initial parameters provided by strategy\n",
      "INFO flwr 2023-03-09 18:41:51,499 | server.py:88 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 3ms/step - loss: 2.3759 - accuracy: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-03-09 18:41:53,026 | server.py:91 | initial parameters (loss, other metrics): 2.3758909702301025, {'accuracy': 0.10100000351667404}\n",
      "INFO flwr 2023-03-09 18:41:53,027 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-03-09 18:41:53,027 | server.py:215 | fit_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 2.3758909702301025 / accuracy 0.10100000351667404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=26192)\u001b[0m 2023-03-09 18:41:56.120036: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26192)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26194)\u001b[0m 2023-03-09 18:41:56.120726: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26194)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26191)\u001b[0m 2023-03-09 18:41:56.120036: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26191)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26194)\u001b[0m 2023-03-09 18:42:08.118889: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26194)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26191)\u001b[0m 2023-03-09 18:42:08.118889: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26191)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26192)\u001b[0m 2023-03-09 18:42:08.142872: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26192)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=26192)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26194)\u001b[0m [Client 7] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26191)\u001b[0m [Client 2] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:42:10,536 | server.py:229 | fit_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2023-03-09 18:42:10,550 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 3s - loss: 2.3383 - accuracy: 0.1562\n",
      "3/3 [==============================] - 2s 8ms/step - loss: 2.3278 - accuracy: 0.1354\n",
      "3/3 [==============================] - 2s 6ms/step - loss: 2.4652 - accuracy: 0.0729\n",
      "3/3 [==============================] - 2s 9ms/step - loss: 2.4325 - accuracy: 0.1250\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.3251 - accuracy: 0.1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-03-09 18:42:10,760 | server.py:116 | fit progress: (1, 2.325075387954712, {'accuracy': 0.10899999737739563}, 17.73327980702743)\n",
      "DEBUG flwr 2023-03-09 18:42:10,764 | server.py:165 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 2.325075387954712 / accuracy 0.10899999737739563\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26192)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26194)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26191)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:42:14,887 | server.py:179 | evaluate_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2023-03-09 18:42:14,890 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-03-09 18:42:14,891 | server.py:215 | fit_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step - loss: 2.2953 - accuracy: 0.0900\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26192)\u001b[0m [Client 1] loss:2.295255422592163, accuracy:0.09000000357627869\n",
      "4/4 [==============================] - 1s 2ms/step - loss: 2.3975 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26194)\u001b[0m [Client 6] loss:2.397548198699951, accuracy:0.07999999821186066\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 2.2803 - accuracy: 0.1000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26191)\u001b[0m [Client 2] loss:2.2802581787109375, accuracy:0.10000000149011612\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26194)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26191)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26192)\u001b[0m [Client 6] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:42:20,453 | server.py:229 | fit_round 2 received 3 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 4ms/step - loss: 2.4118 - accuracy: 0.0521\n",
      "3/3 [==============================] - 2s 7ms/step - loss: 2.3668 - accuracy: 0.1250\n",
      "3/3 [==============================] - 2s 11ms/step - loss: 2.4535 - accuracy: 0.1562\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.2725 - accuracy: 0.1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-03-09 18:42:20,737 | server.py:116 | fit progress: (2, 2.2725231647491455, {'accuracy': 0.1120000034570694}, 27.709961996995844)\n",
      "DEBUG flwr 2023-03-09 18:42:20,743 | server.py:165 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 2.2725231647491455 / accuracy 0.1120000034570694\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26191)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26194)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26192)\u001b[0m [Client 3] evaluate, config: {}\n",
      "4/4 [==============================] - 1s 5ms/step - loss: 2.2857 - accuracy: 0.1000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26194)\u001b[0m [Client 6] loss:2.285738945007324, accuracy:0.10000000149011612\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 2.2597 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26191)\u001b[0m [Client 5] loss:2.259690046310425, accuracy:0.1599999964237213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:42:29,047 | server.py:179 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-03-09 18:42:29,048 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3027 - accuracy: 0.1500\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26192)\u001b[0m [Client 3] loss:2.30271053314209, accuracy:0.15000000596046448\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26192)\u001b[0m [Client 0] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26194)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=26191)\u001b[0m [Client 7] fit, config: {}\n",
      "1/3 [=========>....................] - ETA: 3s - loss: 2.1691 - accuracy: 0.2500\n",
      "1/3 [=========>....................] - ETA: 3s - loss: 2.3942 - accuracy: 0.0938\n",
      "3/3 [==============================] - 2s 81ms/step - loss: 2.2765 - accuracy: 0.1771\n",
      "3/3 [==============================] - 2s 93ms/step - loss: 2.4362 - accuracy: 0.1042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:42:34,111 | server.py:229 | fit_round 3 received 3 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 13ms/step - loss: 2.3294 - accuracy: 0.1562\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 2.3215 - accuracy: 0.1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-03-09 18:42:34,379 | server.py:116 | fit progress: (3, 2.3214502334594727, {'accuracy': 0.11299999803304672}, 41.35100747901015)\n",
      "DEBUG flwr 2023-03-09 18:42:34,382 | server.py:165 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 2.3214502334594727 / accuracy 0.11299999803304672\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26191)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26192)\u001b[0m [Client 4] evaluate, config: {}\n",
      "4/4 [==============================] - 1s 5ms/step - loss: 2.3150 - accuracy: 0.1100\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26192)\u001b[0m [Client 4] loss:2.314965009689331, accuracy:0.10999999940395355\n",
      "4/4 [==============================] - 1s 5ms/step - loss: 2.3455 - accuracy: 0.1400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26191)\u001b[0m [Client 3] loss:2.3455028533935547, accuracy:0.14000000059604645\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26192)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 18:42:38,464 | server.py:179 | evaluate_round 3 received 3 results and 0 failures\n",
      "INFO flwr 2023-03-09 18:42:38,465 | server.py:144 | FL finished in 45.43772968597477\n",
      "INFO flwr 2023-03-09 18:42:38,467 | app.py:202 | app_fit: losses_distributed [(1, 2.3243539333343506), (2, 2.2827131748199463), (3, 2.321775436401367)]\n",
      "INFO flwr 2023-03-09 18:42:38,468 | app.py:203 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2023-03-09 18:42:38,469 | app.py:204 | app_fit: losses_centralized [(0, 2.3758909702301025), (1, 2.325075387954712), (2, 2.2725231647491455), (3, 2.3214502334594727)]\n",
      "INFO flwr 2023-03-09 18:42:38,473 | app.py:205 | app_fit: metrics_centralized {'accuracy': [(0, 0.10100000351667404), (1, 0.10899999737739563), (2, 0.1120000034570694), (3, 0.11299999803304672)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 2.3049 - accuracy: 0.1400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=26192)\u001b[0m [Client 2] loss:2.304858446121216, accuracy:0.14000000059604645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 2.3243539333343506\n",
       "\tround 2: 2.2827131748199463\n",
       "\tround 3: 2.321775436401367\n",
       "History (loss, centralized):\n",
       "\tround 0: 2.3758909702301025\n",
       "\tround 1: 2.325075387954712\n",
       "\tround 2: 2.2725231647491455\n",
       "\tround 3: 2.3214502334594727\n",
       "History (metrics, centralized):\n",
       "{'accuracy': [(0, 0.10100000351667404), (1, 0.10899999737739563), (2, 0.1120000034570694), (3, 0.11299999803304672)]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The `evaluate` function will be by Flower called after every round -> return function to avoid model loading overhead\n",
    "def get_evaluate_fn(model):\n",
    "    def evaluate(server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar]) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "        dataset = test_dataset # Check if this name is the appropriate according to the developed exercise. It should be a Tuple\n",
    "        set_parameters(model, parameters)  # Update model with the latest parameters\n",
    "        loss, accuracy = test(model, dataset)\n",
    "        print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "    return evaluate\n",
    "\n",
    "# Model to initialize the global model and allow evaluation\n",
    "model = generate_ann() \n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.3,\n",
    "    fraction_evaluate=0.3,\n",
    "    min_fit_clients=3,\n",
    "    min_evaluate_clients=3,\n",
    "    min_available_clients=10,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(model)),\n",
    "    evaluate_fn=get_evaluate_fn(model),  # Pass the evaluation function\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffb7e9",
   "metadata": {},
   "source": [
    "Additionally, it is possible to implement a custom strategy from scratch by implementing the necessary methods and extending `flwr.server.strategy.Strategy`. The required methods for a custom strategy are as follows:\n",
    "* `num_fit_clients`: returns the number of clients to be selected for the next round of training.\n",
    "* `num_rounds`: returns the number of rounds of training to perform.\n",
    "* `on_fit`: called when a client has completed training and returned its updated model. This method should update the global model based on the returned model.\n",
    "* `on_evaluate`: called when a client has completed an evaluation and returned its evaluation result. This method should aggregate the evaluation results.\n",
    "\n",
    "\n",
    "You can see an schema of the methods and an example in the following [link](https://flower.dev/docs/tutorial/Flower-3-Building-a-Strategy-PyTorch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a7905",
   "metadata": {},
   "source": [
    "# Challenges for Federated Learning\n",
    "\n",
    "While federated learning can solve problems that traditional centralized machine learning struggles with, such as privacy and reduced hardware requirements, it also presents its own challenges. In this section, we will cover some of these challenges, including the non-IID (independent and identically distributed) nature of the data, the heterogeneous nature of devices, and the limited communication bandwidth.\n",
    "\n",
    "## Non-IID data\n",
    "The assumption of independence and identical distribution, or i.i.d., is commonly made in machine learning and statistical analysis. This means that each data point is independent of all other data points, and that the distribution of the data is the same across all data points.\n",
    "\n",
    "Non-i.i.d. data, on the other hand, violates one or both of these assumptions. This can occur for a variety of reasons. For example, data may be collected in a way that introduces dependencies between data points, such as when data is collected over time or in a specific order. Additionally, the distribution of the data may vary across different subgroups or regions, making it non-i.i.d. Non-i.i.d. data is a common challenge in federated learning because the data is distributed across many devices, and each device may have a different distribution of data due to variations in data collection methods or data sources. As a result, traditional machine learning algorithms may not perform well on non-i.i.d. data.\n",
    "\n",
    "In a non-IID data problem (see Figure 1(a)), \"non-IIDness\" (see Figure 1(c)) refers to the presence of couplings (such as co-occurrence, neighborhood, dependency, linkage, correlation, and causality) and heterogeneities within and between two or more aspects, such as entities, entity classes, entity properties (variables), processes, facts, and states of affairs, or other types of entities or properties (such as learners and learned results) that appear or are produced prior to, during, and after a target process (such as a learning task). Conversely, IIDness ignores or simplifies these relationships, as shown in Figure 1(b).\n",
    "\n",
    "![Diagram with IID and non-IID data](https://datasciences.org/wp-content/themes/dslabNew/images/datasciences/IIDness.png)\n",
    "Credit: [Source of the image](https://datasciences.org/non-iid-learning/)\n",
    "\n",
    "Non-i.i.d. data can be more challenging to work with than i.i.d. data because standard statistical assumptions and techniques may not be applicable. Therefore, special techniques may need to be employed to analyze non-i.i.d. data, which may include techniques that take into account the dependencies between data points or the varying data distributions.\n",
    "\n",
    "In this context, non-i.i.d. data refers to the fact that the data on each device may differ in terms of distribution, characteristics, and relevance to the task at hand. For instance, the data on one device may comprise mainly images of dogs, while the data on another device may consist mainly of images of cats. This can pose a challenge in training a model that performs well on all the devices because the data on each device can vary significantly from the data on the other devices.\n",
    "\n",
    "To address non-i.i.d. data in federated learning, special techniques are often employed to weigh the contributions of each device's data to the overall model, or to adjust the model's parameters in a way that considers the differences in the data. Furthermore, techniques such as data augmentation and transfer learning could help to generalize the model beyond the device's data.\n",
    "\n",
    "When discussing Flower, the approach to addressing this problem would involve implementing a custom strategy, similar to the following example, that uses a custom aggregation of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf098de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-03-09 19:22:20,364 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-03-09 19:22:28,913\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO flwr 2023-03-09 19:22:30,670 | app.py:179 | Flower VCE: Ray initialized with resources: {'memory': 2454972827.0, 'object_store_memory': 1227486412.0, 'CPU': 4.0, 'node:127.0.0.1': 1.0}\n",
      "INFO flwr 2023-03-09 19:22:30,674 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-03-09 19:22:30,676 | server.py:266 | Using initial parameters provided by strategy\n",
      "INFO flwr 2023-03-09 19:22:30,678 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2023-03-09 19:22:30,679 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-03-09 19:22:30,680 | server.py:215 | fit_round 1: strategy sampled 3 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27570)\u001b[0m 2023-03-09 19:22:33.617484: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27570)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27571)\u001b[0m 2023-03-09 19:22:33.618037: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27571)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27568)\u001b[0m 2023-03-09 19:22:33.617484: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27568)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27571)\u001b[0m 2023-03-09 19:22:43.143017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27571)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27568)\u001b[0m 2023-03-09 19:22:43.144866: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27568)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27570)\u001b[0m 2023-03-09 19:22:43.236434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27570)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=27571)\u001b[0m [Client 9] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27568)\u001b[0m [Client 6] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27570)\u001b[0m [Client 5] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:22:45,156 | server.py:229 | fit_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2023-03-09 19:22:45,176 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-03-09 19:22:45,178 | server.py:165 | evaluate_round 1: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 12ms/step - loss: 2.2383 - accuracy: 0.1875\n",
      "3/3 [==============================] - 1s 12ms/step - loss: 2.4179 - accuracy: 0.1042\n",
      "3/3 [==============================] - 1s 12ms/step - loss: 2.3147 - accuracy: 0.1354\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27570)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27571)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27568)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:22:48,826 | server.py:179 | evaluate_round 1 received 3 results and 0 failures\n",
      "WARNING flwr 2023-03-09 19:22:48,827 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-03-09 19:22:48,828 | server.py:215 | fit_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 1s - loss: 2.2104 - accuracy: 0.1250\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 2.2310 - accuracy: 0.1700\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27570)\u001b[0m [Client 1] loss:2.231018304824829, accuracy:0.17000000178813934\n",
      "Round 1 accuracy aggregated from client results: 0.16000000139077505\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2447 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27571)\u001b[0m [Client 2] loss:2.2446885108947754, accuracy:0.1599999964237213\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2289 - accuracy: 0.1500\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27568)\u001b[0m [Client 0] loss:2.228919744491577, accuracy:0.15000000596046448\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27571)\u001b[0m [Client 8] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27570)\u001b[0m [Client 2] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27568)\u001b[0m [Client 4] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:22:54,209 | server.py:229 | fit_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-03-09 19:22:54,223 | server.py:165 | evaluate_round 2: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 4ms/step - loss: 2.3486 - accuracy: 0.0833\n",
      "3/3 [==============================] - 2s 4ms/step - loss: 2.3328 - accuracy: 0.1354\n",
      "3/3 [==============================] - 2s 4ms/step - loss: 2.2966 - accuracy: 0.1146\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27570)\u001b[0m [Client 3] evaluate, config: {}\n",
      "1/4 [======>.......................] - ETA: 2s - loss: 2.3639 - accuracy: 0.0625\n",
      "4/4 [==============================] - 1s 6ms/step - loss: 2.3024 - accuracy: 0.1300\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27570)\u001b[0m [Client 3] loss:2.302405595779419, accuracy:0.12999999523162842\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27570)\u001b[0m [Client 7] evaluate, config: {}\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3134 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27570)\u001b[0m [Client 7] loss:2.3133928775787354, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27570)\u001b[0m [Client 6] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:23:00,083 | server.py:179 | evaluate_round 2 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-03-09 19:23:00,085 | server.py:215 | fit_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step - loss: 2.2497 - accuracy: 0.1800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27570)\u001b[0m [Client 6] loss:2.2496886253356934, accuracy:0.18000000715255737\n",
      "Round 2 accuracy aggregated from client results: 0.14333333323399225\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27570)\u001b[0m [Client 3] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27571)\u001b[0m [Client 4] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27568)\u001b[0m [Client 5] fit, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27571)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=27568)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:23:04,817 | server.py:229 | fit_round 3 received 3 results and 0 failures\n",
      "DEBUG flwr 2023-03-09 19:23:04,830 | server.py:165 | evaluate_round 3: strategy sampled 3 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 4ms/step - loss: 2.3214 - accuracy: 0.1562\n",
      "3/3 [==============================] - 2s 4ms/step - loss: 2.3347 - accuracy: 0.1250\n",
      "3/3 [==============================] - 2s 3ms/step - loss: 2.3477 - accuracy: 0.1250\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27568)\u001b[0m [Client 7] evaluate, config: {}\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.3862 - accuracy: 0.1100\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27568)\u001b[0m [Client 7] loss:2.386219024658203, accuracy:0.10999999940395355\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27571)\u001b[0m [Client 0] evaluate, config: {}\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2786 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27571)\u001b[0m [Client 0] loss:2.278578996658325, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27568)\u001b[0m [Client 5] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:23:09,938 | server.py:179 | evaluate_round 3 received 3 results and 0 failures\n",
      "INFO flwr 2023-03-09 19:23:09,939 | server.py:144 | FL finished in 39.25867025798652\n",
      "INFO flwr 2023-03-09 19:23:09,942 | app.py:202 | app_fit: losses_distributed [(1, 2.234875520070394), (2, 2.2884956995646157), (3, 2.3180171648661294)]\n",
      "INFO flwr 2023-03-09 19:23:09,944 | app.py:203 | app_fit: metrics_distributed {'accuracy': [(1, 0.16000000139077505), (2, 0.14333333323399225), (3, 0.11999999731779099)]}\n",
      "INFO flwr 2023-03-09 19:23:09,945 | app.py:204 | app_fit: losses_centralized []\n",
      "INFO flwr 2023-03-09 19:23:09,946 | app.py:205 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3 accuracy aggregated from client results: 0.11999999731779099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 2.234875520070394\n",
       "\tround 2: 2.2884956995646157\n",
       "\tround 3: 2.3180171648661294\n",
       "History (metrics, distributed):\n",
       "{'accuracy': [(1, 0.16000000139077505), (2, 0.14333333323399225), (3, 0.11999999731779099)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 2.2893 - accuracy: 0.1300\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=27568)\u001b[0m [Client 5] loss:2.2892534732818604, accuracy:0.12999999523162842\n"
     ]
    }
   ],
   "source": [
    "from flwr.common import EvaluateRes, FitRes, Scalar\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "\n",
    "class AggregateCustomMetricStrategy(fl.server.strategy.FedAvg):\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation accuracy using weighted average.\"\"\"\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Call aggregate_evaluate from base class (FedAvg) to aggregate loss and metrics\n",
    "        aggregated_loss, aggregated_metrics = super().aggregate_evaluate(server_round, results, failures)\n",
    "\n",
    "        # Weigh accuracy of each client by number of examples used\n",
    "        accuracies = [r.metrics[\"accuracy\"] * r.num_examples for _, r in results]\n",
    "        examples = [r.num_examples for _, r in results]\n",
    "\n",
    "        # Aggregate and print custom metric\n",
    "        aggregated_accuracy = sum(accuracies) / sum(examples)\n",
    "        print(f\"Round {server_round} accuracy aggregated from client results: {aggregated_accuracy}\")\n",
    "\n",
    "        # Return aggregated loss and metrics (i.e., aggregated accuracy)\n",
    "        return aggregated_loss, {\"accuracy\": aggregated_accuracy}\n",
    "\n",
    "# Model to initialize the global model and allow evaluation\n",
    "model = generate_ann()\n",
    "\n",
    "# Create strategy and run server\n",
    "strategy = AggregateCustomMetricStrategy(\n",
    "    fraction_fit=0.3,\n",
    "    fraction_evaluate=0.3,\n",
    "    min_fit_clients=3,\n",
    "    min_evaluate_clients=3,\n",
    "    min_available_clients=10,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(model)),\n",
    ")\n",
    "\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a017a00",
   "metadata": {},
   "source": [
    "## Heterogeneity of the devices\n",
    "\n",
    "The heterogeneity of the devices in the network, which means they may have different hardware and software configurations and may be running different versions of the operating system, is one of the problems of federated learning. This can lead to several problems, including:\n",
    "\n",
    "* Inefficient communication: Different devices may have varying network speeds and bandwidth, which can make it difficult to transmit model updates between devices in a timely manner.\n",
    "\n",
    "* Incompatible updates: If different devices are running different versions of the operating systems, they may not be able to exchange model updates due to compatibility issues.\n",
    "\n",
    "* Data heterogeneity: The data on different devices may differ in terms of quality, quantity, and format, making it challenging to train a model that generalizes well across all devices.\n",
    "\n",
    "\n",
    "\n",
    "To mitigate the impact of heterogeneous devices in federated learning, researchers are developing techniques such as device-aware aggregation algorithms and communication optimization. These techniques aim to address issues such as inefficient communication and incompatible updates resulting from differences in network speeds, bandwidth, operating system versions, and data heterogeneity across the devices.\n",
    "\n",
    "\n",
    "Consider a network of five devices (A, B, C, D, and E) that are participating in federated learning to train a global model. Each device has its own data and trains a local model on that data. The local models are then transmitted back to a central server, where they are aggregated and used to update the global model.\n",
    "\n",
    "\n",
    "In the above scenario, the participating devices (A, B, C, D, and E) in the federated learning network are heterogeneous in nature, meaning they possess different hardware and software configurations. For instance, Device A and Device B may be running distinct versions of the operating system, and Device C may have a slower network connection in comparison to the other devices.\n",
    "\n",
    "\n",
    "This heterogeneity in the devices can create challenges in the federated learning process. For instance, Device A may face difficulty sending its local model update to the server because of compatibility issues with Device B, and Device C may experience a slower transmission due to its slower network connection.\n",
    "\n",
    "\n",
    "To overcome the challenges posed by heterogeneous devices in federated learning, researchers are developing techniques to mitigate their impact. These techniques may include device-aware aggregation algorithms, which take into account the different hardware and software configurations of the devices, and communication optimization techniques such as data compression and intelligent routing. By adapting the way that data is aggregated and transmitted, these techniques can help to ensure that all devices are able to contribute effectively to the global model, regardless of their individual characteristics.\n",
    "\n",
    "\n",
    "\n",
    "It is also worth mentioning that a local configuration can be provided to the `Clients` by means of the `config` parameter of the function in the `FlowerClient`. This parameter is a Python `Dict` which holds values that can be used internally for different purposes, such as limiting the number of epochs on certain clients or establishing the number of rounds.\n",
    "\n",
    "\n",
    "The modification for the strategy in this case would require the use of parameter `on_fit_config` to indicate the function to retrieve the correct configuration.\n",
    "\n",
    "\n",
    "```python\n",
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict for each round.\n",
    "\n",
    "    Perform two rounds of training with one local epoch, increase to two local\n",
    "    epochs afterwards.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"server_round\": server_round,  # The current round of federated learning\n",
    "        \"local_epochs\": 1 if server_round < 2 else 2,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.3,\n",
    "    fraction_evaluate=0.3,\n",
    "    min_fit_clients=3,\n",
    "    min_evaluate_clients=3,\n",
    "    min_available_clients=10,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(model)),\n",
    "    evaluate_fn=evaluate,\n",
    "    on_fit_config_fn=fit_config,  # Pass the fit_config function\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "However, sometimes limiting the number of rounds or the number of epochs for each client is not enough, especially when the number of clients is too large to handle. In such cases, it may be necessary to reduce the number of clients used for training and evaluation. For instance, consider a scenario where there are 1000 clients, each with only 50 samples for training and 10 for evaluation. Although the amount of data in each client is limited, the communication overhead can still be overwhelming. In such cases, it is better to train for a longer time with a smaller number of clients in each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43fd3f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:48:33.287257: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO flwr 2023-03-09 19:48:33,420 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-03-09 19:48:38,304\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO flwr 2023-03-09 19:48:41,124 | app.py:179 | Flower VCE: Ray initialized with resources: {'object_store_memory': 1054105190.0, 'node:127.0.0.1': 1.0, 'CPU': 4.0, 'memory': 2108210382.0}\n",
      "INFO flwr 2023-03-09 19:48:41,126 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-03-09 19:48:41,128 | server.py:266 | Using initial parameters provided by strategy\n",
      "INFO flwr 2023-03-09 19:48:41,136 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2023-03-09 19:48:41,140 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-03-09 19:48:41,145 | server.py:215 | fit_round 1: strategy sampled 20 clients (out of 40)\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m 2023-03-09 19:48:49.699584: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m 2023-03-09 19:48:50.163709: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m 2023-03-09 19:48:50.637724: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m 2023-03-09 19:48:50.734146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m 2023-03-09 19:49:08.696584: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m 2023-03-09 19:49:08.973515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 18] fit, config: {'server_round': 1, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m 2023-03-09 19:49:09.396017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 29] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 6] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "3/3 [==============================] - 1s 11ms/step - loss: 2.4016 - accuracy: 0.1354\n",
      "3/3 [==============================] - 1s 7ms/step - loss: 2.3621 - accuracy: 0.1354\n",
      "3/3 [==============================] - 2s 15ms/step - loss: 2.4959 - accuracy: 0.1354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m 2023-03-09 19:49:13.784267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 32] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 2] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 30] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 19] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "3/3 [==============================] - 4s 5ms/step - loss: 2.4566 - accuracy: 0.0833\n",
      "3/3 [==============================] - 5s 35ms/step - loss: 2.5960 - accuracy: 0.1354\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 33] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 28] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m \n",
      "3/3 [==============================] - 4s 7ms/step - loss: 2.5517 - accuracy: 0.1250\n",
      "3/3 [==============================] - 4s 5ms/step - loss: 2.6885 - accuracy: 0.0833\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 13] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 34] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "3/3 [==============================] - 3s 12ms/step - loss: 2.5008 - accuracy: 0.0625\n",
      "3/3 [==============================] - 4s 6ms/step - loss: 2.6499 - accuracy: 0.1354\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 20] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "3/3 [==============================] - 4s 9ms/step - loss: 2.5637 - accuracy: 0.0833\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 25] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "3/3 [==============================] - 4s 13ms/step - loss: 2.5249 - accuracy: 0.1250\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 22] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 38] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "1/3 [=========>....................] - ETA: 8s - loss: 2.3790 - accuracy: 0.2188\n",
      "3/3 [==============================] - 4s 7ms/step - loss: 2.4861 - accuracy: 0.1458\n",
      "3/3 [==============================] - 3s 13ms/step - loss: 2.4936 - accuracy: 0.1146\n",
      "1/3 [=========>....................] - ETA: 5s - loss: 2.4461 - accuracy: 0.0938\n",
      "3/3 [==============================] - 3s 5ms/step - loss: 2.5160 - accuracy: 0.1458\n",
      "3/3 [==============================] - 3s 17ms/step - loss: 2.5402 - accuracy: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 2120 MiB, 32 objects, write throughput 88 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 9] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 11] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 21] fit, config: {'server_round': 1, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 16] fit, config: {'server_round': 1, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x10804b010> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 5ms/step - loss: 2.5112 - accuracy: 0.1146\n",
      "1/3 [=========>....................] - ETA: 4s - loss: 2.5931 - accuracy: 0.0312\n",
      "3/3 [==============================] - 2s 23ms/step - loss: 2.5893 - accuracy: 0.0521\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 31] fit, config: {'server_round': 1, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x110f14c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 4ms/step - loss: 2.3278 - accuracy: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x16f6ca9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 12ms/step - loss: 2.5615 - accuracy: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:49:42,266 | server.py:229 | fit_round 1 received 20 results and 0 failures\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x161e493f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING flwr 2023-03-09 19:49:42,395 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-03-09 19:49:42,412 | server.py:165 | evaluate_round 1: strategy sampled 40 clients (out of 40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 3ms/step - loss: 2.6312 - accuracy: 0.1458\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 27] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 11] evaluate, config: {}\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.5337 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 27] loss:2.5336692333221436, accuracy:0.20000000298023224\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.3776 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 24] loss:2.3775529861450195, accuracy:0.20000000298023224\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 7] evaluate, config: {}\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2.3543 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 28] loss:2.3542935848236084, accuracy:0.20000000298023224\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3253 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 11] loss:2.325331211090088, accuracy:0.20000000298023224\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2959 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 7] loss:2.295869827270508, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 34] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4004 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 34] loss:2.400387763977051, accuracy:0.11999999731779099\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4027 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 4] loss:2.4027206897735596, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 30] evaluate, config: {}\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3282 - accuracy: 0.1200\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 2.3282 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 30] loss:2.3281564712524414, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 3] evaluate, config: {}\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4244 - accuracy: 0.1600\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3826 - accuracy: 0.1200\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 2.4244 - accuracy: 0.1600\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 2.4195 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 36] loss:2.3826096057891846, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 1] loss:2.424386501312256, accuracy:0.1599999964237213\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 2.4110 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 16] loss:2.4110054969787598, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 3] loss:2.4194772243499756, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 37] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 39] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m \n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3559 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 37] loss:2.3558664321899414, accuracy:0.07999999821186066\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4589 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 0] loss:2.458925247192383, accuracy:0.07999999821186066\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 32] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 2.3426 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 32] loss:2.3425629138946533, accuracy:0.07999999821186066\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.6206 - accuracy: 0.0000e+00\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 39] loss:2.6205785274505615, accuracy:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x161daa3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 19] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 2] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x16a84f5b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 2.4399 - accuracy: 0.0400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 8] loss:2.4399139881134033, accuracy:0.03999999910593033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x1084acdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 2.4304 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 19] loss:2.4303934574127197, accuracy:0.1599999964237213\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2630 - accuracy: 0.2400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 2] loss:2.2629523277282715, accuracy:0.23999999463558197\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 38] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x11624c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 4355 MiB, 62 objects, write throughput 103 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 2.3502 - accuracy: 0.1600\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3193 - accuracy: 0.0400\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3502 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 38] loss:2.3502159118652344, accuracy:0.1599999964237213\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3193 - accuracy: 0.0400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 23] loss:2.3192715644836426, accuracy:0.03999999910593033\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 14] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 18] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 2.2542 - accuracy: 0.2400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 6] loss:2.2541916370391846, accuracy:0.23999999463558197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x16a982050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x16fbca290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x16a2b5a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 750ms/step - loss: 2.3754 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 14] loss:2.375392436981201, accuracy:0.1599999964237213\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 2.2886 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 17] loss:2.2885820865631104, accuracy:0.1599999964237213\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2350 - accuracy: 0.1600\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 2.2350 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 18] loss:2.2350082397460938, accuracy:0.1599999964237213\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 9] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 2.2210 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 12] loss:2.221000909805298, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m \n",
      "1/1 [==============================] - 1s 917ms/step - loss: 2.3071 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 9] loss:2.307131290435791, accuracy:0.1599999964237213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x16a2b6440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 508ms/step - loss: 2.4368 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 5] loss:2.436832904815674, accuracy:0.07999999821186066\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 13] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m \n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3575 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 20] loss:2.357529401779175, accuracy:0.20000000298023224\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 10] evaluate, config: {}\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4693 - accuracy: 0.1600\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.4693 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 13] loss:2.4692983627319336, accuracy:0.1599999964237213\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 31] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3607 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 10] loss:2.360715866088867, accuracy:0.07999999821186066\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 2.3830 - accuracy: 0.0000e+00\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 31] loss:2.3829643726348877, accuracy:0.0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 22] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 2.3673 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 35] loss:2.3673293590545654, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 29] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3287 - accuracy: 0.1200\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2969 - accuracy: 0.2400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 22] loss:2.2968623638153076, accuracy:0.23999999463558197\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 26] loss:2.328659772872925, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 15] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 2.2772 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 25] loss:2.2772490978240967, accuracy:0.11999999731779099\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 2.2242 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 29] loss:2.224151849746704, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 21] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 2.2596 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 33] loss:2.259556770324707, accuracy:0.11999999731779099\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 2.3851 - accuracy: 0.0000e+00\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 15] loss:2.3850927352905273, accuracy:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:50:42,917 | server.py:179 | evaluate_round 1 received 40 results and 0 failures\n",
      "WARNING flwr 2023-03-09 19:50:42,918 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-03-09 19:50:42,919 | server.py:215 | fit_round 2: strategy sampled 20 clients (out of 40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 294ms/step - loss: 2.4147 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 21] loss:2.4146716594696045, accuracy:0.20000000298023224\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 25] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 39] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 26] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 13] fit, config: {'server_round': 2, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x16fbca0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x16a2b6200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 5s - loss: 2.3641 - accuracy: 0.2500\n",
      "3/3 [==============================] - 3s 11ms/step - loss: 2.4180 - accuracy: 0.1875\n",
      "1/3 [=========>....................] - ETA: 5s - loss: 2.2580 - accuracy: 0.1250\n",
      "3/3 [==============================] - 3s 14ms/step - loss: 2.3703 - accuracy: 0.1562\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 11] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 10] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "3/3 [==============================] - 4s 25ms/step - loss: 2.3423 - accuracy: 0.1146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x16a982f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 8ms/step - loss: 2.5057 - accuracy: 0.0417\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 20] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 22] fit, config: {'server_round': 2, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x16a1db490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 5ms/step - loss: 2.3402 - accuracy: 0.1458\n",
      "3/3 [==============================] - 4s 7ms/step - loss: 2.4859 - accuracy: 0.0833\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 38] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 2] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "3/3 [==============================] - 4s 22ms/step - loss: 2.4038 - accuracy: 0.1146\n",
      "3/3 [==============================] - 4s 21ms/step - loss: 2.3900 - accuracy: 0.0833\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 30] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "3/3 [==============================] - 3s 10ms/step - loss: 2.4260 - accuracy: 0.0833\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.4950 - accuracy: 0.0833\n",
      "3/3 [==============================] - 3s 38ms/step - loss: 2.4950 - accuracy: 0.0833\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 24] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "3/3 [==============================] - 3s 5ms/step - loss: 2.4320 - accuracy: 0.0833\n",
      "3/3 [==============================] - 2s 4ms/step - loss: 2.3913 - accuracy: 0.0625\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 4] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 6] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 21] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "3/3 [==============================] - 4s 17ms/step - loss: 2.5001 - accuracy: 0.1042\n",
      "3/3 [==============================] - 3s 5ms/step - loss: 2.3818 - accuracy: 0.1562\n",
      "3/3 [==============================] - 2s 5ms/step - loss: 2.5137 - accuracy: 0.1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 8243 MiB, 121 objects, write throughput 125 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 23] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 3] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 29] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 0] fit, config: {'server_round': 2, 'local_epochs': 3}\n",
      "3/3 [==============================] - 2s 4ms/step - loss: 2.4014 - accuracy: 0.0938\n",
      "3/3 [==============================] - 2s 5ms/step - loss: 2.3618 - accuracy: 0.0938\n",
      "3/3 [==============================] - 2s 9ms/step - loss: 2.4978 - accuracy: 0.0938\n",
      "3/3 [==============================] - 2s 9ms/step - loss: 2.4311 - accuracy: 0.1354\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 35] fit, config: {'server_round': 2, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:51:21,777 | server.py:229 | fit_round 2 received 20 results and 0 failures\n",
      "DEBUG flwr 2023-03-09 19:51:21,921 | server.py:165 | evaluate_round 2: strategy sampled 40 clients (out of 40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 5ms/step - loss: 2.6428 - accuracy: 0.0729\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 17] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 19] evaluate, config: {}\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3991 - accuracy: 0.0400\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2385 - accuracy: 0.2000\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2850 - accuracy: 0.1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3380 - accuracy: 0.0400\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3991 - accuracy: 0.0400\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2385 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 36] loss:2.2385036945343018, accuracy:0.20000000298023224\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2850 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 21] loss:2.284980058670044, accuracy:0.11999999731779099\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3380 - accuracy: 0.0400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 17] loss:2.337999105453491, accuracy:0.03999999910593033\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 19] loss:2.399149179458618, accuracy:0.03999999910593033\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 23] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 31] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 27] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:51:32,730 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 5978128384; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 2.3032 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 23] loss:2.30315899848938, accuracy:0.07999999821186066\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3066 - accuracy: 0.0400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 31] loss:2.3065781593322754, accuracy:0.03999999910593033\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3108 - accuracy: 0.0800\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3108 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 24] loss:2.310784101486206, accuracy:0.07999999821186066\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 2.2896 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 27] loss:2.2895586490631104, accuracy:0.1599999964237213\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 16] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 3] evaluate, config: {}\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3563 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 16] loss:2.3562803268432617, accuracy:0.20000000298023224\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 34] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 7] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 2.2877 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 3] loss:2.287710189819336, accuracy:0.1599999964237213\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 2.4254 - accuracy: 0.0000e+00\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 34] loss:2.4253952503204346, accuracy:0.0\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 2.3712 - accuracy: 0.0400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 7] loss:2.371238946914673, accuracy:0.03999999910593033\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 22] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 14] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 2.2985 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 22] loss:2.2985341548919678, accuracy:0.07999999821186066\n",
      "1/1 [==============================] - 1s 771ms/step - loss: 2.2957 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 14] loss:2.295734167098999, accuracy:0.1599999964237213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:51:44,392 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 6032142336; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 9] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 2.2603 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 25] loss:2.2602803707122803, accuracy:0.20000000298023224\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 2.3035 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 9] loss:2.3034636974334717, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 12] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 33] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 1] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3495 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 12] loss:2.349508762359619, accuracy:0.07999999821186066\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 26] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3789 - accuracy: 0.0400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 33] loss:2.3788580894470215, accuracy:0.03999999910593033\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3408 - accuracy: 0.1200\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3408 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 20] loss:2.3407716751098633, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 15] evaluate, config: {}\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3051 - accuracy: 0.1200\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2.3051 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 1] loss:2.3051207065582275, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 18] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:51:54,460 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 5915181056; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 2.3776 - accuracy: 0.0400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 26] loss:2.377572774887085, accuracy:0.03999999910593033\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 8] evaluate, config: {}\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2645 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 15] loss:2.2644760608673096, accuracy:0.1599999964237213\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 2.3576 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 18] loss:2.3575730323791504, accuracy:0.07999999821186066\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 2.2916 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 8] loss:2.2915542125701904, accuracy:0.1599999964237213\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 0] evaluate, config: {}\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 2.3726 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 0] loss:2.37263560295105, accuracy:0.07999999821186066\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 11] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 28] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 29] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:52:04,525 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 5783990272; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 2.4214 - accuracy: 0.0400\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3998 - accuracy: 0.0800\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3170 - accuracy: 0.1200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3766 - accuracy: 0.1200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.4214 - accuracy: 0.0400\n",
      "1/1 [==============================] - 6s 6s/step - loss: 2.3998 - accuracy: 0.0800\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3170 - accuracy: 0.1200\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.3766 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 11] loss:2.4214484691619873, accuracy:0.03999999910593033\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 4] loss:2.3169753551483154, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 28] loss:2.376584768295288, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 29] loss:2.3997864723205566, accuracy:0.07999999821186066\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 32] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 38] evaluate, config: {}\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2698 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 32] loss:2.269789218902588, accuracy:0.11999999731779099\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.4270 - accuracy: 0.0400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 38] loss:2.4270222187042236, accuracy:0.03999999910593033\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 35] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:52:22,170 | server.py:179 | evaluate_round 2 received 32 results and 8 failures\n",
      "DEBUG flwr 2023-03-09 19:52:22,176 | server.py:215 | fit_round 3: strategy sampled 20 clients (out of 40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 2.3855 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 35] loss:2.385455846786499, accuracy:0.07999999821186066\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 29] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 11] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 7] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 25] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.3976 - accuracy: 0.1458\n",
      "3/3 [==============================] - 4s 40ms/step - loss: 2.3298 - accuracy: 0.0833\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.3998 - accuracy: 0.1042\n",
      "3/3 [==============================] - 4s 41ms/step - loss: 2.4161 - accuracy: 0.1458\n",
      "3/3 [==============================] - 4s 42ms/step - loss: 2.3976 - accuracy: 0.1458\n",
      "3/3 [==============================] - 4s 44ms/step - loss: 2.3998 - accuracy: 0.1042\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 35] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "3/3 [==============================] - 3s 23ms/step - loss: 2.3702 - accuracy: 0.1042\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 16] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 5] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 27] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "3/3 [==============================] - 2s 24ms/step - loss: 2.2577 - accuracy: 0.1875\n",
      "1/3 [=========>....................] - ETA: 5s - loss: 2.2835 - accuracy: 0.1562\n",
      "3/3 [==============================] - 3s 60ms/step - loss: 2.3428 - accuracy: 0.1146\n",
      "3/3 [==============================] - 3s 13ms/step - loss: 2.3230 - accuracy: 0.1250\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 22] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "1/3 [=========>....................] - ETA: 4s - loss: 2.3058 - accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 99ms/step - loss: 2.3232 - accuracy: 0.1042\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 3] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 2] fit, config: {'server_round': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:53:23,627 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 5933330432; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 30] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "1/3 [=========>....................] - ETA: 4s - loss: 2.2886 - accuracy: 0.0938\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.3483 - accuracy: 0.1250\n",
      "3/3 [==============================] - 3s 115ms/step - loss: 2.3483 - accuracy: 0.1250\n",
      "1/3 [=========>....................] - ETA: 4s - loss: 2.3899 - accuracy: 0.0938\n",
      "3/3 [==============================] - 3s 112ms/step - loss: 2.3583 - accuracy: 0.1250\n",
      "3/3 [==============================] - 2s 30ms/step - loss: 2.4030 - accuracy: 0.1562\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28563)\u001b[0m [Client 18] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28565)\u001b[0m [Client 17] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 33] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28562)\u001b[0m [Client 8] fit, config: {'server_round': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:53:33,714 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 4897927168; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 18ms/step - loss: 2.3311 - accuracy: 0.1042\n",
      "3/3 [==============================] - 3s 10ms/step - loss: 2.3921 - accuracy: 0.0833\n",
      "3/3 [==============================] - 3s 6ms/step - loss: 2.4083 - accuracy: 0.0729\n",
      "3/3 [==============================] - 3s 10ms/step - loss: 2.3145 - accuracy: 0.1771\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 20] fit, config: {'server_round': 3, 'local_epochs': 3}\n",
      "3/3 [==============================] - 1s 13ms/step - loss: 2.3127 - accuracy: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:53:43,803 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 4432818176; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 0] fit, config: {'server_round': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:53:53,887 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 4309217280; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 4ms/step - loss: 2.3555 - accuracy: 0.1250\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=28564)\u001b[0m [Client 9] fit, config: {'server_round': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:53:55,502 | server.py:229 | fit_round 3 received 19 results and 1 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 7ms/step - loss: 2.3125 - accuracy: 0.1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:53:55,808 | server.py:165 | evaluate_round 3: strategy sampled 40 clients (out of 40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 21] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 35] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 19] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:54:03,971 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 4129984512; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 2.2995 - accuracy: 0.0800\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3053 - accuracy: 0.0800\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3808 - accuracy: 0.0800\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2868 - accuracy: 0.1200\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2995 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 21] loss:2.2994577884674072, accuracy:0.07999999821186066\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3053 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 35] loss:2.305265188217163, accuracy:0.07999999821186066\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3808 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 0] loss:2.3808329105377197, accuracy:0.07999999821186066\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2868 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 19] loss:2.286755084991455, accuracy:0.11999999731779099\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 33] evaluate, config: {}\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3404 - accuracy: 0.0400\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3404 - accuracy: 0.0400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 33] loss:2.340394973754883, accuracy:0.03999999910593033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:54:13,986 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 4097896448; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 3] evaluate, config: {}\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2009 - accuracy: 0.2800\n",
      "1/1 [==============================] - 1s 754ms/step - loss: 2.2009 - accuracy: 0.2800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 3] loss:2.2009012699127197, accuracy:0.2800000011920929\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 24] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m \n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2909 - accuracy: 0.0800\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2909 - accuracy: 0.0800\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 24] loss:2.290864944458008, accuracy:0.07999999821186066\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 11] evaluate, config: {}\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 2.2309 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 11] loss:2.230862617492676, accuracy:0.1599999964237213\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 20] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m \n",
      "1/1 [==============================] - 0s 478ms/step - loss: 2.2913 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 20] loss:2.2912511825561523, accuracy:0.20000000298023224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:54:24,015 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 4178939904; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 36] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 25] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 26] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 31] evaluate, config: {}\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3031 - accuracy: 0.0000e+00\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m \n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3031 - accuracy: 0.0000e+00\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 36] loss:2.3031258583068848, accuracy:0.0\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 10] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m \n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2212 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 25] loss:2.2212255001068115, accuracy:0.11999999731779099\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2875 - accuracy: 0.0400\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 31] loss:2.2875072956085205, accuracy:0.03999999910593033\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 4] evaluate, config: {}\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2257 - accuracy: 0.1600\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 22] evaluate, config: {}\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2539 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 26] loss:2.2256531715393066, accuracy:0.1599999964237213\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m \n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m \n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2539 - accuracy: 0.2000\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28564)\u001b[0m [Client 10] loss:2.2538504600524902, accuracy:0.20000000298023224\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 1] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:54:34,079 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 3524849664; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 2.3194 - accuracy: 0.1200\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2879 - accuracy: 0.0400\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.3194 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28562)\u001b[0m [Client 4] loss:2.319409132003784, accuracy:0.11999999731779099\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2899 - accuracy: 0.1200\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28565)\u001b[0m [Client 22] loss:2.287884473800659, accuracy:0.03999999910593033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-03-09 19:54:35,247 | server.py:179 | evaluate_round 3 received 17 results and 23 failures\n",
      "INFO flwr 2023-03-09 19:54:35,253 | server.py:144 | FL finished in 354.10427461203653\n",
      "INFO flwr 2023-03-09 19:54:35,271 | app.py:202 | app_fit: losses_distributed [(1, 2.3619590520858766), (2, 2.3345150724053383), (3, 2.283243277493645)]\n",
      "INFO flwr 2023-03-09 19:54:35,274 | app.py:203 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2023-03-09 19:54:35,277 | app.py:204 | app_fit: losses_centralized []\n",
      "INFO flwr 2023-03-09 19:54:35,278 | app.py:205 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=28563)\u001b[0m [Client 1] loss:2.289893865585327, accuracy:0.11999999731779099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 2.3619590520858766\n",
       "\tround 2: 2.3345150724053383\n",
       "\tround 3: 2.283243277493645"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-03-09 19:54:44,094 E 28559 4984833] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-03-09_19-48-33_583684_28501 is over 95% full, available space: 4048863232; capacity: 121018208256. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "# Be careful with this cell. It's a time consuming process\n",
    "n_clients = 40\n",
    "\n",
    "train_datasets, val_datasets, test_datasets = split_dataset(train_dataset, test_dataset, n_clients)\n",
    "\n",
    "# Also you can define the generation function of CLients for a stateless version\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    # Create the model\n",
    "    net = generate_ann()\n",
    "    #Take the appropiate part of the dataset\n",
    "    trainloader = train_datasets[int(cid)]\n",
    "    valloader = val_datasets[int(cid)]\n",
    "    #Create and return the Client\n",
    "    return FlowerClient(cid, net, trainloader, valloader)\n",
    "\n",
    "# Model to initialize the global model and allow evaluation\n",
    "model = generate_ann()\n",
    "\n",
    "def fit_config(server_round: int):\n",
    "    config = {\n",
    "        \"server_round\": server_round,\n",
    "        \"local_epochs\": 3,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=0.025,  # Train on 25 clients (each round)\n",
    "    fraction_evaluate=0.05,  # Evaluate on 50 clients (each round)\n",
    "    min_fit_clients=20,\n",
    "    min_evaluate_clients=40,\n",
    "    min_available_clients=n_clients,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(get_parameters(model)),\n",
    "    on_fit_config_fn=fit_config,\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=n_clients,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f1abb",
   "metadata": {},
   "source": [
    "In addition to the techniques mentioned earlier, federated transfer learning, secure aggregation, and data augmentation are other approaches that can help in the scaling of the federated learning system. The limitation of resources, including bandwidth, storage, and computation power, is one of the main challenges of federated learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
